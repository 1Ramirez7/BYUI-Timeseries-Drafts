{
  "hash": "ecd8b7ffb07de335ef2ab884e2b424f5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Fitted AR Models\"\nsubtitle: \"Chapter 4: Lesson 4\"\nformat: html\neditor: source\nsidebar: false\n---\n\n\n\n\n\n\n## Learning Outcomes\n\n\n<details>\n\n<summary>Fit time series models to data and interpret fitted parameters</summary>\n-   Fit an $AR(p)$ model to simulated data\n-   Explain the difference between parameters of the data generating process and estimates\n-   Calculate confidence intervals for AR coefficient estimates\n-   Interpret AR coefficient estimates in the context of the source and nature of historical data\n\n</details>\n\n\n\n<details>\n\n<summary>Check model adequacy using diagnostic plots like correlograms of residuals</summary>\n-   Compare AR fitted models to an underlying data generating process\n-   Explain the limitations of stochastic model fitting as evidence in favor or against real world arguments.\n\n</details>\n\n\n\n\n\n\n## Preparation\n\n-   Read Sections 4.6-4.7\n\n\n\n## Learning Journal Exchange (10 min)\n\n-   Review another student's journal\n\n-   What would you add to your learning journal after reading another student's?\n\n-   What would you recommend the other student add to their learning journal?\n\n-   Sign the Learning Journal review sheet for your peer\n\n\n\n\n\n## Class Activity: Fitting a Simulated $AR(1)$ Model with Zero Mean (5 min)\n\nWe will demonstrate how AR models are fitted via simulation. We will fit two different $AR(1)$ models and an $AR(2)$ model. The advantage of using simulation is that we know how the time series was constructed. So, we know the model that was used and the actual values of the parameters in that model. We can then see how close our estimated parameter values are to the true values.\n\n### Simulate an $AR(1)$ Time Series\n\nIn this simulation, we first simulate data from the $AR(1)$ model\n$$\n  x_t = 0.75 ~ x_{t-1} + w_t\n$$\nwhere $w_t$ is a white noise process with variance 1.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nset.seed(123)\nn_rep <- 1000\nalpha1 <- 0.75\n\ndat_ts <- tibble(w = rnorm(n_rep)) |>\n  mutate(\n    index = 1:n(),\n    x = purrr::accumulate2(\n      lag(w), w, \n      \\(acc, nxt, w) alpha1 * acc + w,\n      .init = 0)[-1]) |>\n  tsibble::as_tsibble(index = index)\n\ndat_ts |> \n  autoplot(.vars = x) +\n    labs(\n      x = \"Time\",\n      y = \"Simulated Time Series\",\n      title = \"Simulated Values from an AR(1) Process\"\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\nThe R command `mean(dat_ts$x)` gives the mean of the $x_t$ values as 0.067.\n\n### Fit an $AR(1)$ Model with Zero Mean\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Fit the AR(1) model\nfit_ar <- dat_ts |>\n  model(AR(x ~ order(1)))\ntidy(fit_ar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  .model           term  estimate std.error statistic   p.value\n  <chr>            <chr>    <dbl>     <dbl>     <dbl>     <dbl>\n1 AR(x ~ order(1)) ar1      0.720    0.0220      32.8 2.07e-160\n```\n\n\n:::\n:::\n\n\n\nThe estimate of the parameter $\\alpha_1$ (i.e. the fitted value of the parameter $\\alpha_1$) is $\\hat \\alpha_1 = 0.72$. \n\nWhen R fits an AR model, the mean of the time series is subtracted from the data before the parameter values are estimated. \nIf R detects that the mean of the time series is not significantly different from zero, it is omitted from the output.\n\nBecause the mean is subtracted from the time series before the parameter values are estimated, R is using the model\n$$\n  z_t = \\alpha_1 ~ z_{t-1} + w_t\n$$\nwhere $z_t = x_t - \\mu$ and $\\mu$ is the mean of the time series.\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\nAnswer the following questions with your partner.\n\n-   Use the expression for $z_t$ above to solve for $x_t$ in terms of $x_{t-1}$, $\\mu$, $\\alpha_1$, and $w_t$.\n-   What does your model reduce to when $\\mu = 0$?\n-   Explain to your partner why this correctly models a time series with mean $\\mu$.\n\n:::\n\nWe replace the parameter $\\mu$ with its estimator $\\hat \\mu = \\bar x$. We also replace $\\alpha_1$ with the fitted value from the output $\\hat \\alpha_1$. This gives us the fitted model:\n$$\n  \\hat x_t = \\bar x + \\hat \\alpha_1 ~ (x_{t-1} - \\bar x)\n$$\n\nThe fitted model can be expressed as:\n\n\\begin{align*}\n  \\hat x_t \n    &= 0.067 + 0.72 \\left( x_{t-1} - 0.067 \\right) \\\\\n    &= 0.067 - 0.72 ~ (0.067) + 0.72 ~ \\left( x_{t-1} \\right) \\\\\n    &= 0.019 + 0.72 ~ x_{t-1} \n\\end{align*}\n\nEven though R does not report the parameter for the mean of the process, $\\hat \\mu = 0.019$, it is not significantly different from zero. One could argue that we should not use a model that contains the mean and instead focus on a simple fitted model that has only one parameter:\n\n$$\n  \\hat x_t = 0.72 ~ x_{t-1}\n$$\n\n### Confidence Interval for the Model Parameter\n\nThe P-value given above tests the hypothesis that $\\alpha_1=0$. This is not helpful in this context. We are interested in the plausible values for $\\alpha_1$, not whether or not it is different from zero. For this reason, we consider a confidence interval and disregard the P-value.\n\nWe can compute an approximate 95% confidence interval for $\\alpha_1$ as:\n$$\n  \\left( \n    \\hat \\alpha_1 - 2 \\cdot SE_{\\hat \\alpha_1}\n    , ~ \n    \\hat \\alpha_1 + 2 \\cdot SE_{\\hat \\alpha_1}\n  \\right)\n$$\nwhere $\\hat \\alpha_1$ is our parameter estimate and $SE_{\\hat \\alpha_1}$ is the standard error of the estimate. Both of these values are given in the R output.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nci_summary <- tidy(fit_ar) |>\n    mutate(\n        lower = estimate - 2 * std.error,\n        upper = estimate + 2 * std.error\n    )\n```\n:::\n\n\n\nSo, our 95% confidence interval for $\\alpha_1$ is:\n$$\n  \\left(\n  0.72 - 2 \\cdot 0.022\n  , ~\n  0.72 + 2 \\cdot 0.022\n  \\right)\n$$\nor\n$$\n  \\left(\n  0.676\n  , ~\n  0.764\n  \\right)\n$$\nNote that the confidence interval contains $\\alpha_1 = 0.75$, the value of the parameter we used in our simulation. The process of estimating the parameter worked well. In practice, we will not know the value of $\\alpha_1$, but the confidence interval gives us a reasonable estimate of the value.\n\n\n### Residuals\n\nFor an $AR(1)$ model where the mean of the time series is not statistically significantly different from 0, the residuals are computed as\n\\begin{align*}\n  r_t \n    &= x_t - \\hat x_t \\\\\n    &= x_t - \\left[ 0.72 ~ x_{t-1} \\right] \n\\end{align*}\n\n\n\n\n\n\n\nWe can easily obtain these residual values in R:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nfit_ar |> residuals()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 1,000 x 3 [1]\n# Key:       .model [1]\n   .model           index .resid\n   <chr>            <int>  <dbl>\n 1 AR(x ~ order(1))     1 NA    \n 2 AR(x ~ order(1))     2 -0.247\n 3 AR(x ~ order(1))     3  1.54 \n 4 AR(x ~ order(1))     4  0.103\n 5 AR(x ~ order(1))     5  0.156\n 6 AR(x ~ order(1))     6  1.74 \n 7 AR(x ~ order(1))     7  0.531\n 8 AR(x ~ order(1))     8 -1.20 \n 9 AR(x ~ order(1))     9 -0.675\n10 AR(x ~ order(1))    10 -0.458\n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n\nThe variance of the residuals is $0.982$.\nThis is very close to the actual value used in the simulation: $\\sigma^2 = 1$.\n\n\n\n\n\n Start of the next section \n These parameters are used in the simulation below \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha0 <- 50\nalpha1 <- 0.75\nsigma_sqr <- 5\n```\n:::\n\n\n\n## Class Activity: Fitting a Simulated $AR(1)$ Model with Non-Zero Mean (5 min)\n\n### Simulate an $AR(1)$ Time Series\n\nIt is easy to conceive situations where the mean of an AR model, $\\mu$, is not zero. \nThe model we have been fitting is\n$$\n  x_t = \\mu + \\alpha_1 ~ \\left( x_{t-1} - \\mu \\right) + w_t\n$$\nwhere $\\mu$ and $\\alpha_1$ are constants, and $w_t$ is a white noise process with variance $\\sigma^2$.\n\nThis model can be simplified by combining like terms.\n\\begin{align*}\nx_t \n  &= \\mu + \\alpha_1 ~ \\left( x_{t-1} - \\mu \\right) + w_t \\\\\n  &= \\underbrace{\\mu - \\alpha_1 ~ (\\mu)}_{\\alpha_0} + \\alpha_1 ~ \\left( x_{t-1} \\right) + w_t \\\\\n  &= \\alpha_0 + \\alpha_1 ~ \\left( x_{t-1} \\right) + w_t \n\\end{align*}\n\nSuppose the mean of the $AR(1)$ process is $\\mu = 50$. We will set $\\alpha_1 = 0.75$, and $\\sigma^2 = 5$ for this simulation.\nAfter specifying these numbers, the model becomes:\n\\begin{align*}\n  x_t \n    &= 50 + 0.75 ~ ( x_{t-1} - 50 ) + w_t \\\\\n    &= 50 - 0.75 ~ ( 50 ) + 0.75 ~ x_{t-1} + w_t \\\\\n    &= 12.5 + 0.75 ~ x_{t-1} + w_t \n\\end{align*}\nwhere $w_t$ is a white noise process with variance $\\sigma^2 = 5$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nset.seed(123)\nn_rep <- 1000\nalpha1 <- 0.75\nsigma_sqr <- 5\n\ndat_ts <- tibble(w = rnorm(n = n_rep, sd = sqrt(sigma_sqr))) |>\n  mutate(\n    index = 1:n(),\n    x = purrr::accumulate2(\n      lag(w), w, \n      \\(acc, nxt, w) alpha1 * acc + w,\n      .init = 0)[-1]) |>\n  mutate(x = x + alpha0) |> \n  tsibble::as_tsibble(index = index)\n\ndat_ts |> \n  autoplot(.vars = x) +\n    labs(\n      x = \"Time\",\n      y = \"Simulated Time Series\",\n      title = \"Simulated Values from an AR(1) Process\"\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nThe R command `mean(dat_ts$x)` gives the mean of the $x_t$ values as 50.15.\n\n### Fit an $AR(1)$ Model with Non-Zero Mean\n\nWe now use R to fit an $AR(1)$ model to the time series data. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Fit the AR(1) model\nfit_ar <- dat_ts |>\n  model(AR(x ~ order(1)))\ntidy(fit_ar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .model           term     estimate std.error statistic   p.value\n  <chr>            <chr>       <dbl>     <dbl>     <dbl>     <dbl>\n1 AR(x ~ order(1)) constant   14.1      1.11        12.7 1.35e- 34\n2 AR(x ~ order(1)) ar1         0.719    0.0220      32.7 5.95e-160\n```\n\n\n:::\n:::\n\n\n\nThe estimate of the parameter for the constant (mean) term $\\alpha_0$ is $\\hat \\alpha_0 = 14.091$.\nThe estimate of the parameter $\\alpha_1$ (i.e. the fitted value of the parameter $\\alpha_1$) is $\\hat \\alpha_1 = 0.719$. \n\n Recall that the mean of the time series is subtracted from the data before the parameter values are estimated. To estimate the time series, start with the mean and then add the coefficient $\\hat \\alpha_1$ multiplied by the difference between $x_{t-1}$ and the mean. \n\nFitting the model\n$$\n  x_t = \\alpha_0 + \\alpha_1 ~ x_{t-1} + w_t \n$$\nwe get\n\\begin{align*}\n  \\hat x_t \n    &= \\hat \\alpha_0 + \\hat \\alpha_1 ~ x_{t-1} \\\\\n    &= 14.091 + \n      0.719\n         ~ x_{t-1}\n\\end{align*}\n\n\n### Confidence Intervals for the Model Parameters\n\nWe can compute approximate 95% confidence intervals for $\\alpha_0$ and $\\alpha_1$:\n\n$$\n  \\left( \n    \\hat \\alpha_i - 2 \\cdot SE_{\\hat \\alpha_i}\n    , ~ \n    \\hat \\alpha_i + 2 \\cdot SE_{\\hat \\alpha_i}\n  \\right)\n$$\nwhere $\\hat \\alpha_i$ is our estimate of parameter $i \\in \\{0,1\\}$, and $SE_{\\hat \\alpha_i}$ is the standard error of the respective estimates.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nci_summary <- tidy(fit_ar) |>\n    mutate(\n        lower = estimate - 2 * std.error,\n        upper = estimate + 2 * std.error\n    )\n```\n:::\n\n\n\n Beginning of two columns \n\n\n95% Confidence Interval for $\\alpha_0$:\n$$\n  \\left( \n    \\hat \\alpha_0 - 2 \\cdot SE_{\\hat \\alpha_0}\n    , ~ \n    \\hat \\alpha_0 + 2 \\cdot SE_{\\hat \\alpha_0}\n  \\right)\n$$\n\n$$\n  \\left(\n  14.091 - 2 \\cdot 1.105\n  , ~\n  14.091 + 2 \\cdot 1.105\n  \\right)\n$$\n\n$$\n  \\left(\n  11.88\n  , ~\n  16.301\n  \\right)\n$$\nThe confidence interval for $\\alpha_0$ contains \n$$\\alpha_0 = \\mu - \\alpha_1 ~ (\\mu) = 12.5$$\n\n\n empty column to create gap \n\n\n95% Confidence Interval for $\\alpha_1$:\n$$\n  \\left( \n    \\hat \\alpha_1 - 2 \\cdot SE_{\\hat \\alpha_1}\n    , ~ \n    \\hat \\alpha_1 + 2 \\cdot SE_{\\hat \\alpha_1}\n  \\right)\n$$\n\n$$\n  \\left(\n  0.719 - 2 \\cdot 0.022\n  , ~\n  0.719 + 2 \\cdot 0.022\n  \\right)\n$$\n\n$$\n  \\left(\n  0.675\n  , ~\n  0.763\n  \\right)\n$$\nThe confidence interval for $\\alpha_1$ contains \n$$\\alpha_1 = 0.75$$\n\n\n End of two columns \n\nBoth intervals captured the true value used in the simulation. The process of estimating the parameter worked well. In practice, we will not know the value of $\\alpha_1$, but the confidence interval gives us a reasonable estimate of the value.\nAbout 95% of the time, the confidence interval will capture the true parameter value.\n\n\n\n### Residuals\n\nThe residuals in this model are computed as\n\\begin{align*}\n  r_t \n    &= x_t - \\hat x_t \\\\\n    &= x_t - \n      \\left[ \n        14.091 + \n      0.719\n         ~ x_{t-1}\n      \\right] \n\\end{align*}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nfit_ar |> residuals()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 1,000 x 3 [1]\n# Key:       .model [1]\n   .model           index .resid\n   <chr>            <int>  <dbl>\n 1 AR(x ~ order(1))     1 NA    \n 2 AR(x ~ order(1))     2 -0.596\n 3 AR(x ~ order(1))     3  3.40 \n 4 AR(x ~ order(1))     4  0.190\n 5 AR(x ~ order(1))     5  0.308\n 6 AR(x ~ order(1))     6  3.85 \n 7 AR(x ~ order(1))     7  1.15 \n 8 AR(x ~ order(1))     8 -2.72 \n 9 AR(x ~ order(1))     9 -1.55 \n10 AR(x ~ order(1))    10 -1.07 \n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThe variance of the residuals is $4.911$, which is near the actual parameter value: $\\sigma^2 = 5$.\n\n\n\n\n\n\n\n## Class Activity: Fitting a Simulated $AR(2)$ Model (10 min)\n\n### Simulate an $AR(2)$ Time Series\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set parameters\nalpha0 <- 20\nalpha1 <- 0.5\nalpha2 <- 0.4\nsigma_sqr <- 9\n```\n:::\n\n\n\n\nIn this section, we will simulate data from the following $AR(2)$ process:\n$$\n  x_t = 2 + 0.5 ~ x_{t-1} + 0.4 ~ x_{t-2} + w_t\n$$\nwhere $w_t$ is a discrete white noise process with variance $\\sigma^2 = 9$.\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\nUse the $AR(2)$ process above to answer the following questions.\n\n-   Is this $AR(2)$ process stationary? (Hint: The characteristic polynomial only includes terms that involve $x_t$.)\n-   Rewrite the model in the form\n$$\n  x_t = \\mu + \\alpha_1 ~ ( x_{t-1} - \\mu) + \\alpha_2 ~ ( x_{t-2} - \\mu) + w_t\n$$\n    Identify the value of each of the coefficients ($\\mu$, $\\alpha_1$, and $\\alpha_2$).\n Solution Solution Solution Solution Solution Solution \n \\begin{align*} \n   x_t  \n     &= 20 + 0.5 ~ ( x_{t-1} - 20) + 0.4 ~ ( x_{t-2} - 20) + w_t \\\\ \n     &= 2 + 0.5 ~ x_{t-1} + 0.4 ~ x_{t-2} + w_t \n \\end{align*} \n-   What is the mean of this $AR(2)$ process?\n\n:::\n\nHere is a time plot of the simulated time series.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nset.seed(123)\nn_rep <- 1000\nalpha0 <- 20\nalpha1 <- 0.5\nalpha2 <- 0.4\nsigma_sqr <- 9\n\ndat_ts <- tibble(w = rnorm(n = n_rep, sd = sqrt(sigma_sqr))) |>\n    mutate(\n      index = 1:n(),\n      x = 0\n    ) |>\n    tsibble::as_tsibble(index = index)\n\n# Simulate x values\ndat_ts$x[1] <- alpha0 + dat_ts$w[1]\ndat_ts$x[2] <- alpha0 + alpha1 * ( dat_ts$x[1] - alpha0 ) + dat_ts$w[2]\nfor (i in 3:nrow(dat_ts)) {\n  dat_ts$x[i] <- alpha0 + \n    alpha1 * ( dat_ts$x[i-1] - alpha0 ) + \n    alpha2 * ( dat_ts$x[i-2] - alpha0 ) + \n    dat_ts$w[i]\n}\n\ndat_ts |> \n  autoplot(.vars = x) +\n    labs(\n      x = \"Time\",\n      y = \"Simulated Time Series\",\n      title = paste(\"Simulated Values from an AR(2) Process with Mean\", alpha0)\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n### Fit an $AR(2)$ Model \n\nWe fit an $AR(2)$ model to these simulated values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Fit the AR(2) model\nfit_ar <- dat_ts |>\n    model(AR(x ~ order(2))) \ntidy(fit_ar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  .model           term     estimate std.error statistic  p.value\n  <chr>            <chr>       <dbl>     <dbl>     <dbl>    <dbl>\n1 AR(x ~ order(2)) constant    2.33     0.380       6.14 1.17e- 9\n2 AR(x ~ order(2)) ar1         0.478    0.0289     16.5  1.75e-54\n3 AR(x ~ order(2)) ar2         0.408    0.0289     14.1  1.96e-41\n```\n\n\n:::\n:::\n\n\n\nThe estimates of the parameter values are:  \n$\\hat \\alpha_0 = 2.333$, \n$\\hat \\alpha_1 = 0.478$, \nand \n$\\hat \\alpha_2 = 0.408$. \nThis means that our fitted model can be expressed as:\n\n\\begin{align*}\n  \\hat x_t \n  &= \n    \\hat \\alpha_0\n    + \\hat \\alpha_1 ~ x_{t-1}\n    + \\hat \\alpha_2 ~ x_{t-2}\n    \\\\\n  &=\n    2.333 \n    + \n    0.478 \n    ~ x_{t-1} \n    + \n    0.408 \n    ~ x_{t-2} \n\\end{align*}\n\n\n### Confidence Interval for the Model Parameters\n\nWe can compute an approximate 95% confidence interval for $\\alpha_i$ as:\n$$\n  \\left( \n    \\hat \\alpha_i - 2 \\cdot SE_{\\hat \\alpha_i}\n    , ~ \n    \\hat \\alpha_i + 2 \\cdot SE_{\\hat \\alpha_i}\n  \\right)\n$$\nwhere $\\hat \\alpha_i$ is our estimate of the $i^{th}$ parameter and $SE_{\\hat \\alpha_i}$ is the standard error of the respective estimate. These values are given in the R output from the code below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nci_summary <- tidy(fit_ar) |>\n    mutate(\n        lower = estimate - 2 * std.error,\n        upper = estimate + 2 * std.error\n    )\n```\n:::\n\n\n\n\n\n\n Beginning of three columns \n\n95% confidence interval for $\\alpha_0$:\n$$\n  \\left( \n    \\hat \\alpha_0 - 2 \\cdot SE_{\\hat \\alpha_0}\n    , ~ \n    \\hat \\alpha_0 + 2 \\cdot SE_{\\hat \\alpha_0}\n  \\right)\n$$\n$$\n  \\left(\n  2.333 - 2 \\cdot 0.38\n  , \n  \\right.\n  ~~~~~~~~~~~~~~~~~~~\n$$ \n$$ \n  ~~~~~~~~~~~~~~~~~~~\n  \\left.\n  2.333 + 2 \\cdot 0.38\n  \\right)\n$$\n$$\n  \\left(\n  1.574\n  , ~\n  3.093\n  \\right)\n$$\nThis confidence interval contains $\\alpha_0 = 2$.\n\n empty column to create gap \n\n\n95% confidence interval for $\\alpha_1$:\n$$\n  \\left( \n    \\hat \\alpha_1 - 2 \\cdot SE_{\\hat \\alpha_1}\n    , ~ \n    \\hat \\alpha_1 + 2 \\cdot SE_{\\hat \\alpha_1}\n  \\right)\n$$\n$$\n  \\left(\n  0.478 - 2 \\cdot 0.029\n  , \n  \\right.\n  ~~~~~~~~~~~~~~~~~~~\n  $$ \n  $$ \n  ~~~~~~~~~~~~~~~~~~~\n  \\left.\n  0.478 + 2 \\cdot 0.029\n  \\right)\n$$\n$$\n  \\left(\n  0.42\n  , ~\n  0.536\n  \\right)\n$$\nThis confidence interval contains $\\alpha_1 = 0.5$.\n\n empty column to create gap \n\n95% confidence interval for $\\alpha_2$:\n$$\n  \\left( \n    \\hat \\alpha_2 - 2 \\cdot SE_{\\hat \\alpha_2}\n    , ~ \n    \\hat \\alpha_2 + 2 \\cdot SE_{\\hat \\alpha_2}\n  \\right)\n$$\n$$\n  \\left(\n  0.408 - 2 \\cdot 0.029\n  , \n  \\right.\n  ~~~~~~~~~~~~~~~~~~~\n  $$ \n  $$ \n  ~~~~~~~~~~~~~~~~~~~\n  \\left.\n  0.408 + 2 \\cdot 0.029\n  \\right)\n$$\n$$\n  \\left(\n  0.35\n  , ~\n  0.466\n  \\right)\n$$\nThis confidence interval contains $\\alpha_2 = 0.4$.\n\n\n End of three columns \n\nAll three confidence intervals contain the true parameter values we used for the simulation.\n\n\n### Residuals\n\nWe can compute the residuals in the same manner as we did for the other models.\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\nWorking with a partner, do the following\n\n-   Write the expression used to compute the residuals.\n-   Find the residuals of this sequence using your expression.\n-   Here are the first few residuals. Compare these to the values you computed.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nfit_ar |>\n  residuals()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 1,000 x 3 [1]\n# Key:       .model [1]\n   .model           index .resid\n   <chr>            <int>  <dbl>\n 1 AR(x ~ order(2))     1 NA    \n 2 AR(x ~ order(2))     2 NA    \n 3 AR(x ~ order(2))     3  4.60 \n 4 AR(x ~ order(2))     4  0.237\n 5 AR(x ~ order(2))     5  0.330\n 6 AR(x ~ order(2))     6  5.13 \n 7 AR(x ~ order(2))     7  1.46 \n 8 AR(x ~ order(2))     8 -3.78 \n 9 AR(x ~ order(2))     9 -2.13 \n10 AR(x ~ order(2))    10 -1.39 \n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n-   Explain why there are no residuals for times $t=1$ and $t=2$.\n\n:::\n\nThe variance of the residuals is 8.857. This is close to 9, the parameter used in the simulation.\n\n\n\n\n\n\n## Small-Group Activity: Global Warming (20 min)\n\nid=GlobalWarmingThe time plot below illustrates the change in global \nsurface temperature compared to the long-term average \nobserved from 1951 to 1980. (Source: NASA/GISS.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntemps_ts <- rio::import(\"https://byuistats.github.io/timeseries/data/global_temparature.csv\") |>\n  as_tsibble(index = year)\n\ntemps_ts |> autoplot(.vars = change) +\n    labs(\n      x = \"Year\",\n      y = \"Temperature Change (Celsius)\",\n      title = paste0(\"Change in Mean Annual Global Temperature (\", min(temps_ts$year), \"-\", max(temps_ts$year), \")\")\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n### Using the PACF to Choose $p$ for an $AR(p)$ Process\n\nIn the [previous lesson](https://byuistats.github.io/timeseries/chapter_4_lesson_3.html#pacfTable), we noted that the partial correlogram can be used to assess the number of parameters in an AR model.\nHere is a partial correlogram for the change in the mean annual global temperature.\n\n pacf(stock_ts$value, plot=TRUE, lag.max = 25) \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\npacf(temps_ts$change)\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\nWorking with your partner, do the following:\n\n-   We will apply an $AR(p)$ model. What value of $p$ is suggested by the pacf?\n-   Using the value of $p$ you identified, fit an $AR(p)$ model to the global temperature data. State the fitted $AR(p)$ model in the form \n$$\\hat x_t = \\cdots$$\n-   Obtain 95% confidence intervals for each of the parameters. Which are significantly different from zero?\n-   Give the first three residual values (skipping the NAs).\n-   What is the estimate of $\\sigma^2$?\n-   Make a correlogram for the residuals. Does it appear that your model has fully explained the variation in the temperatures?\n\n:::\n\n\n\n\n\n### Fitting Models (Dynamic Number of Parameters)\n\nYou may have concluded that $p=3$ might be insufficient for modeling these data. \nWe now explore a technique that allows R to choose $p$ based on the significance of the parameters.\n\nIf we specify `order(1:9)` in the model statement, R returns the largest $AR(p)$ model (up to $p=9$) for which the parameter $\\alpha_p$ is significant.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglobal_ar <- temps_ts |>\n    model(AR(change ~ order(1:9)))\ntidy(global_ar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 6\n  .model                  term     estimate std.error statistic  p.value\n  <chr>                   <chr>       <dbl>     <dbl>     <dbl>    <dbl>\n1 AR(change ~ order(1:9)) constant   0.0190   0.00881     2.15  3.30e- 2\n2 AR(change ~ order(1:9)) ar1        0.656    0.0841      7.80  1.40e-12\n3 AR(change ~ order(1:9)) ar2       -0.0662   0.100      -0.659 5.11e- 1\n4 AR(change ~ order(1:9)) ar3        0.140    0.0988      1.42  1.58e- 1\n5 AR(change ~ order(1:9)) ar4        0.265    0.0995      2.67  8.58e- 3\n6 AR(change ~ order(1:9)) ar5       -0.163    0.102      -1.60  1.11e- 1\n7 AR(change ~ order(1:9)) ar6        0.206    0.0863      2.38  1.85e- 2\n```\n\n\n:::\n:::\n\n\n\n\nR returned an \n$AR(6)$ \nmodel for this time series.\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\nWorking with your partner, do the following:\n\n-   State the fitted $AR(p)$ model in the form \n$$\\hat x_t = \\cdots$$\n-   Obtain 95% confidence intervals for each of the parameters. Which are significantly different from zero?\n-   Give the first three residual values (skipping the NAs).\n-   What is the estimate of $\\sigma^2$?\n-   Make a correlogram for the residuals. Does it appear that your model has fully explained the variation in the temperatures? Justify your answer.\n\n:::\n\n\n\n\n\n### Stationarity of the $AR(p)$ Model\n\nWith the exception of a lone seemingly spurious autocorrelation, there are no significant values of the acf of the residuals in the \n$AR(6)$ \nmodel. This suggests that the model accounts for the variation in the time series. \n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\n-   Write the characteristic equation for the $AR(6)$ \nmodel you developed.\n-   Click on the link below to obtain a more precise version of the characteristic equation, then solve the characteristic equation by any method.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nalphas <- global_ar |> coefficients() |> tail(-1) |> dplyr::select(estimate) |> pull()\ncat(\n  \"0 = 1\", \n        \"- (\", alphas[1], \") * x\",\n        \"- (\", alphas[2], \") * x^2\",\n        \"- (\", alphas[3], \") * x^3\",\n        \"\\n     \",\n        \"- (\", alphas[4], \") * x^4\",\n        \"- (\", alphas[5], \") * x^5\",\n        \"- (\", alphas[6], \") * x^6\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0 = 1 - ( 0.6559292 ) * x - ( -0.06617426 ) * x^2 - ( 0.140204 ) * x^3 \n      - ( 0.2653744 ) * x^4 - ( -0.1627911 ) * x^5 - ( 0.2056924 ) * x^6\n```\n\n\n:::\n:::\n\n\n\n\n-   Is our $AR(6)$ \nmodel stationary?\n\n:::\n\n\n\n## Class Activity: Forecasting with an $AR(p)$ Model (5 min)\n\nWe now use the model to forecast the mean temperature difference for the next 50 years.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntemps_forecast <- global_ar |> forecast(h = \"50 years\")\ntemps_forecast |>\n  autoplot(temps_ts, level = 95) +\n  geom_line(aes(y = .fitted, color = \"Fitted\"),\n    data = augment(global_ar)) +\n  scale_color_discrete(name = \"\") +\n  labs(\n    x = \"Year\",\n    y = \"Temperature Change (Celsius)\",\n    title = paste0(\"Change in Mean Annual Global Temperature (\", min(temps_ts$year), \"-\", max(temps_ts$year), \")\"),\n    subtitle = paste0(\"50-Year Forecast Based on our AR(\", tidy(global_ar) |> as_tibble() |> dplyr::select(term) |> tail(1) |> right(1), \") Model\")\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n Check your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\n-   Does this forecast seem appropriate for the data? Why or why not?\n\n:::\n\n\n\n\n\n### Class Activity: Comparison to the Results in Section 4.6.3 of the Book (5 min)\n\nIn Sections 1.4.5 and 4.6.3 of the textbook, the authors present a similar dataset on the mean annual temperatures on Earth through 2005. Here is a time plot of their data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglobal_ts <- tibble(x = scan(\"data/global.dat\")) |>\n  mutate(\n        date = seq(\n            ymd(\"1856-01-01\"),\n            by = \"1 months\",\n            length.out = n()),\n        year = year(date),\n        year_month = tsibble::yearmonth(date)\n  ) |>\n  summarise(x = mean(x), .by = year) |>\n  as_tsibble(index = year) \nglobal_ts |> autoplot(.vars = x) +\n    labs(\n      x = \"Year\",\n      y = \"Temperature Change (Celsius)\",\n      title = paste0(\"Change in Mean Annual Global Temperature (\", min(global_ts$year), \"-\", max(global_ts$year), \")\"),\n      subtitle = \"Data from Textbook Sections 1.4.5 and 4.6.3\"\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5),\n      plot.subtitle = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\nThe fitted $AR(4)$ model is given below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglobal_ar_book <- global_ts |>\n  model(AR(x ~ order(1:9)))\ntidy(global_ar_book)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  .model             term  estimate std.error statistic  p.value\n  <chr>              <chr>    <dbl>     <dbl>     <dbl>    <dbl>\n1 AR(x ~ order(1:9)) ar1     0.582     0.0791     7.36  1.24e-11\n2 AR(x ~ order(1:9)) ar2     0.0216    0.0919     0.236 8.14e- 1\n3 AR(x ~ order(1:9)) ar3     0.107     0.0917     1.17  2.43e- 1\n4 AR(x ~ order(1:9)) ar4     0.267     0.0791     3.38  9.43e- 4\n```\n\n\n:::\n:::\n\n\n\nLet's check the stationarity of this model. The characteristic equation is:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nalphas <- global_ar_book |> coefficients() |> dplyr::select(estimate) |> pull()\ncat(\n  \"0 = 1\", \n        \"- (\", alphas[1], \") * x\",\n        \"- (\", alphas[2], \") * x^2\",\n        \"- (\", alphas[3], \") * x^3\",\n        \"- (\", alphas[4], \") * x^4\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0 = 1 - ( 0.5817607 ) * x - ( 0.02164876 ) * x^2 - ( 0.1074731 ) * x^3 - ( 0.2670716 ) * x^4\n```\n\n\n:::\n:::\n\n\n\nThe solutions of the characteristic equation are:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\npolyroot(c(1, -alphas)) |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.011+0.000i -1.755+0.000i  0.171-1.443i  0.171+1.443i\n```\n\n\n:::\n:::\n\n\n\nThe absolute value of the solutions of the characteristic equation are:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\npolyroot(c(1, -alphas)) |> abs() |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.011 1.755 1.453 1.453\n```\n\n\n:::\n:::\n\n\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\n-   Is the textbook's model stationary?\n-   In the textbook, the author stated, \n\"The correlogram of the residuals has only one (marginally) significant value\nat lag 27, so the underlying residual series could be white noise (Fig. 4.14).\nThus the fitted AR(4) model (Equation (4.24)) provides a good fit to the\ndata. As the AR model has no deterministic trend component, the trends in\nthe data can be explained by serial correlation and random variation, implying\nthat it is possible that these trends are stochastic (or could arise from a purely\nstochastic process). Again we emphasise that this does not imply that there is\nno underlying reason for the trends. If a valid scientific explanation is known,\nsuch as a link with the increased use of fossil fuels, then this information would\nclearly need to be included in any future forecasts of the series.\"\n\n    -   What is the author saying?\n    -   How would you respond to this statement?\n\n:::\n\nHere is a plot of the forecasted values for the next 100 years, based on the textbook's model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# global_ar_book <- global_ts |>\n#   model(AR(x ~ order(4)))\ntemps_forecast_book <- global_ar_book |> forecast(h = \"100 years\")\ntemps_forecast_book |>\n  autoplot(global_ts, level = 95) +\n#   geom_line(aes(y = .mean, color = \"Fitted\"),\n#     data = augment(global_ar_book)) +\n#   scale_color_discrete(name = \"\") +\n    labs(\n      x = \"Year\",\n      y = \"Temperature Change (Celsius)\",\n      title = paste0(\"Change in Mean Annual Global Temperature (\", min(temps_ts$year), \"-\", max(temps_ts$year), \")\"),\n      subtitle = \"100-Year Forecast Based on the Book's AR(4) Model\"\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5),\n      plot.subtitle = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n Check Your Understanding \n\n::: {.callout-tip icon=false title=\"Check Your Understanding\"}\n\n-   Compare and contrast the results you observed in the two global temperature time series.\n-   What conclusions do you draw?\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Homework Preview (5 min)\n\n-   Review upcoming homework assignment\n-   Clarify questions\n\n\n\n\n\n\n\n  \nCheck Your Understanding\n\nWorking with your partner, do the following\n\n-   We will apply an $AR(p)$ model. What value of $p$ is suggested by the pacf?\n\n**Solution:**\n\n  $$p=3$$\n\n\n-   Using the value of $p$ you identified, fit an $AR(p)$ model to the global temperature data. State the fitted $AR(p)$ model in the form \n$$\\hat x_t = \\cdots$$\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglobal_ar <- temps_ts |>\n    model(AR(change ~ order(3)))\ntidy(global_ar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  .model                term  estimate std.error statistic  p.value\n  <chr>                 <chr>    <dbl>     <dbl>     <dbl>    <dbl>\n1 AR(change ~ order(3)) ar1     0.737     0.0823     8.95  1.80e-15\n2 AR(change ~ order(3)) ar2    -0.0350    0.103     -0.339 7.35e- 1\n3 AR(change ~ order(3)) ar3     0.319     0.0839     3.80  2.15e- 4\n```\n\n\n:::\n:::\n\n\n\nNote that the constant term is not statistically significant. If we ignore this term, we get the fitted model:\n\n\\begin{align*}\n  \\hat x_t \n  &= \n    0\n    + \\hat \\alpha_1 ~ x_{t-1}\n    + \\hat \\alpha_2 ~ x_{t-2}\n    + \\hat \\alpha_3 ~ x_{t-3}\n    \\\\\n  &=\n    0.737 \n    ~ x_{t-1} \n    + \n    (-0.035)\n    ~ x_{t-2} \n    + \n    0.319 \n    ~ x_{t-3} \n\\end{align*}\n\nIf we want to incorporate the constant term in the model, then we need to find the mean of the time series. The mean of the time series is:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(temps_ts$change)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06923611\n```\n\n\n:::\n:::\n\n\n\nThe fitted AR model is\n\n\\begin{align*}\n  \\hat x_t \n  &= \n    \\hat \\mu\n    + \\hat \\alpha_1 ~ (x_{t-1} - \\mu)\n    + \\hat \\alpha_2 ~ (x_{t-2} - \\mu)\n    + \\hat \\alpha_3 ~ (x_{t-3} - \\mu)\n    \\\\\n  &= \n    \\underbrace{\n    \\hat \\mu - \\hat \\alpha_1 (\\hat \\mu) - \\hat \\alpha_2 (\\hat \\mu) - \\hat \\alpha_3 (\\hat \\mu)\n    }_{\\hat \\alpha_0}\n    + \\hat \\alpha_1 ~ x_{t-1}\n    + \\hat \\alpha_2 ~ x_{t-2}\n    + \\hat \\alpha_3 ~ x_{t-3}\n    \\\\\n  &= \n    \\hat \\alpha_0\n    + \\hat \\alpha_1 ~ x_{t-1}\n    + \\hat \\alpha_2 ~ x_{t-2}\n    + \\hat \\alpha_3 ~ x_{t-3}\n\\end{align*}\nOr, after substituting the fitted values:\n\\begin{align*}\n  \\hat x_t\n  &=\n    0.069 \n    + \n    0.737 \n    ~ ( x_{t-1} - 0.069)\n    + \n    (-0.035)\n    ~ ( x_{t-2} - 0.069) \n    + \n    0.319 \n    ~ ( x_{t-3} - 0.069) \\\\\n  &=\n    -0.0014\n    + \n    0.737 \n    ~ x_{t-1} \n    + \n    (-0.035)\n    ~ x_{t-2} \n    + \n    0.319 \n    ~ x_{t-3} \n\\end{align*}\n\n\n\n-   Obtain 95% confidence intervals for each of the parameters. Which are significantly different from zero?\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nci_summary <- tidy(global_ar) |>\n    mutate(\n        lower = estimate - 2 * std.error,\n        upper = estimate + 2 * std.error\n    )\n```\n:::\n\n\n\nThe confidence intervals are:\n\\begin{align*}\n  \\alpha_1: &&&\n    ( \n      0.572 \n      ,~ \n      0.901 \n    )\n    \\\\\n  \\alpha_2: &&&\n    ( \n      -0.242 \n      ,~ \n      0.172 \n    )\n    \\\\\n  \\alpha_3: &&&\n    ( \n      0.151 \n      ,~ \n      0.486 \n    )\n\\end{align*}\n\nThe parameters $\\alpha_1$ and $\\alpha_3$ are statistically significantly different from 0.\n\n\n-   Give the first three residual values (skipping the NAs).\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_ar |> \n  residuals() |>\n  na.omit() |>\n  head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 3 x 3 [1Y]\n# Key:       .model [1]\n  .model                 year  .resid\n  <chr>                 <int>   <dbl>\n1 AR(change ~ order(3))  1883 -0.0413\n2 AR(change ~ order(3))  1884 -0.130 \n3 AR(change ~ order(3))  1885 -0.105 \n```\n\n\n:::\n:::\n\n\n\n\n-   What is the estimate of $\\sigma^2$?\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nresid_df <- global_ar |> \n  residuals() |>\n  as_tibble()\nvar(resid_df$.resid, na.rm = TRUE) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01114332\n```\n\n\n:::\n:::\n\n\n\n\n\n-   Make a correlogram for the residuals. Does it appear that your model has fully explained the variation in the temperatures?\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nresiduals(global_ar) |> \n  ACF(lag_max = 50) |> \n  autoplot(.vars = .resid) +\n    labs(\n      title = paste0(\"ACF of the Residuals from the AR(\", tidy(global_ar) |> as_tibble() |> dplyr::select(term) |> tail(1) |> right(1), \") Model\")\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nResponse variable not specified, automatically selected `var = .resid`\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\nThere is still a significant autocorrelation at lag $k=3$. This suggests a more sophisticated model may be necessary.\n\n\n End of check your understanding \n\n\n End of UsingPACFglobaltemps solutions \n\n\n\n  DynamicPglobaltemps\n  \n Check Your Understanding \n\nWorking with your partner, do the following:\n\n-   State the fitted $AR(p)$ model in the form \n$$\\hat x_t = \\cdots$$\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglobal_ar <- temps_ts |>\n    model(AR(change ~ order(1:9)))\ntidy(global_ar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 6\n  .model                  term     estimate std.error statistic  p.value\n  <chr>                   <chr>       <dbl>     <dbl>     <dbl>    <dbl>\n1 AR(change ~ order(1:9)) constant   0.0190   0.00881     2.15  3.30e- 2\n2 AR(change ~ order(1:9)) ar1        0.656    0.0841      7.80  1.40e-12\n3 AR(change ~ order(1:9)) ar2       -0.0662   0.100      -0.659 5.11e- 1\n4 AR(change ~ order(1:9)) ar3        0.140    0.0988      1.42  1.58e- 1\n5 AR(change ~ order(1:9)) ar4        0.265    0.0995      2.67  8.58e- 3\n6 AR(change ~ order(1:9)) ar5       -0.163    0.102      -1.60  1.11e- 1\n7 AR(change ~ order(1:9)) ar6        0.206    0.0863      2.38  1.85e- 2\n```\n\n\n:::\n:::\n\n\n\n$$\n  \\hat x_t = \n    0.019\n    +\n    0.656 ~ x_{t-1}\n    +\n    (-0.066) ~ x_{t-2}\n    +\n    0.14 ~ x_{t-3}\n    +\n    0.265 ~ x_{t-4}\n    +\n    (-0.163) ~ x_{t-5}\n    +\n    0.206 ~ x_{t-6}\n$$\n\n-   Obtain 95% confidence intervals for each of the parameters. Which are significantly different from zero?\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nci_summary <- tidy(global_ar) |>\n    mutate(\n        lower = estimate - 2 * std.error,\n        upper = estimate + 2 * std.error\n    )\nci_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 8\n  .model             term  estimate std.error statistic  p.value    lower  upper\n  <chr>              <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>  <dbl>\n1 AR(change ~ order… cons…   0.0190   0.00881     2.15  3.30e- 2  0.00135 0.0366\n2 AR(change ~ order… ar1     0.656    0.0841      7.80  1.40e-12  0.488   0.824 \n3 AR(change ~ order… ar2    -0.0662   0.100      -0.659 5.11e- 1 -0.267   0.135 \n4 AR(change ~ order… ar3     0.140    0.0988      1.42  1.58e- 1 -0.0574  0.338 \n5 AR(change ~ order… ar4     0.265    0.0995      2.67  8.58e- 3  0.0663  0.464 \n6 AR(change ~ order… ar5    -0.163    0.102      -1.60  1.11e- 1 -0.366   0.0405\n7 AR(change ~ order… ar6     0.206    0.0863      2.38  1.85e- 2  0.0331  0.378 \n```\n\n\n:::\n:::\n\n\n\nThe constant term, $\\alpha_1$, $\\alpha_4$, and $\\alpha_6$ are all statistically significantly different from zero.\n\n\n\n-   Give the first three residual values (skipping the NAs).\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nresiduals(global_ar) |>\n  na.omit() |>\n  head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 3 x 3 [1Y]\n# Key:       .model [1]\n  .model                   year  .resid\n  <chr>                   <int>   <dbl>\n1 AR(change ~ order(1:9))  1886 -0.0636\n2 AR(change ~ order(1:9))  1887 -0.117 \n3 AR(change ~ order(1:9))  1888  0.139 \n```\n\n\n:::\n:::\n\n\n\n\n\n-   What is the estimate of $\\sigma^2$?\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nresid_var <- global_ar |>\n  residuals() |>\n  as_tibble() |>\n  dplyr::select(.resid) |>\n  pull() |>\n  na.omit() |>\n  var()\nresid_var\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01006731\n```\n\n\n:::\n:::\n\n\n\nThe estimate of $\\sigma^2$ is $\\hat \\sigma^2 = 0.01$.\n\n\n\n-   Make a correlogram for the residuals. Does it appear that your model has fully explained the variation in the temperatures? Justify your answer.\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nresiduals(global_ar) |> \n  ACF(lag_max = 50) |> \n  autoplot(.vars = .resid) +\n    labs(\n      title = paste0(\"ACF of the Residuals from the AR(\", tidy(global_ar) |> as_tibble() |> dplyr::select(term) |> tail(1) |> right(1), \") Model\")\n    ) +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5)\n    )\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_4_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n\nThere is only one significant autocorrelation: $k=34$. This is probably a Type I error, which should occur 5% of the time. None of the other autocorrelations are significant--particularly among the smaller values of $k$. It appears that this model has fully explained the variation in the temperatures.\n\n\n\n\n End of DynamicPglobaltemps solutions \n\n\n\n\n\n\n\n\n\nStationarity of the $AR(6)$ \nmodel\n\nCharacteristicFunction\n\n Check Your Understanding \n\n\n\n-   Write the characteristic equation for the $AR(6)$ \nmodel you developed.\n\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalphas <- global_ar |> coefficients() |> tail(-1) |> dplyr::select(estimate) |> pull() |> round(3)\ncat(\n  \"0 = 1\", \n        \"- (\", alphas[1], \") * x\",\n        \"- (\", alphas[2], \") * x^2\",\n        \"- (\", alphas[3], \") * x^3\",\n        \"\\n     \",\n        \"- (\", alphas[4], \") * x^4\",\n        \"- (\", alphas[5], \") * x^5\",\n        \"- (\", alphas[6], \") * x^6\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0 = 1 - ( 0.656 ) * x - ( -0.066 ) * x^2 - ( 0.14 ) * x^3 \n      - ( 0.265 ) * x^4 - ( -0.163 ) * x^5 - ( 0.206 ) * x^6\n```\n\n\n:::\n:::\n\n\n\n\n\n\n-   Obtain a more precise version of the characteristic equation, then solve the characteristic equation by any method.\n\n**Solution:**\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n0 = 1 - ( 0.6559292 ) * x - ( -0.06617426 ) * x^2 - ( 0.140204 ) * x^3 \n      - ( 0.2653744 ) * x^4 - ( -0.1627911 ) * x^5 - ( 0.2056924 ) * x^6\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nalphas <- global_ar |> coefficients() |> tail(-1) |> dplyr::select(estimate) |> pull()\npolyroot(c(1, -alphas))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.9838806+0.000000i -1.2890454+0.000000i -0.3076674-1.277838i\n[4]  0.8559646-1.219125i -0.3076674+1.277838i  0.8559646+1.219125i\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n-   Is our $AR(6)$ \nmodel stationary?\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabs(polyroot(c(1, -alphas)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9838806 1.2890454 1.3143548 1.4896112 1.3143548 1.4896112\n```\n\n\n:::\n:::\n\n\n\nNot all of the roots are greater than 1 in absolute value. So, this AR process is not stationary.\n",
    "supporting": [
      "chapter_4_lesson_4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}