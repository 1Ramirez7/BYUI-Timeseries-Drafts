---
title: "Chapter 2: Lesson 3"
subtitle: "Exploration of Autocorrelation Concepts"
format: html
editor: source
---

```{r}
#| include: false
if (!require("pacman")) install.packages("pacman")
pacman::p_load("tsibble", "fable", 
    "feasts", "tsibbledata",
    "fable.prophet", "tidyverse",
    "patchwork",
    "ggthemes", 
    "see",   # okabeito color scheme
    "MASS", # MVNorm
    "ggokabeito", # colorblind palette
    "kableExtra", # formatting tables
    "stringr", # string manipulation
    "lubridate") # date manipulation

palette("okabeito")
okabeito_colors_list <- c(
    `orange` = "#E69F00",
    `light blue` = "#56B4E9",
    `green` = "#009E73",
    `yellow` = "#F0E442",
    `blue` = "#0072B2",
    `red` = "#D55E00",
    `purple` = "#CC79A7",
    `grey` = "#999999",
    `black` = "#000000",
    `sky blue` = "#56B4E9",
    `bluish green` = "#009E73",
    `vermillion` = "#D55E00",
    `reddish purple` = "#CC79A7",
    `dark yellow` = "#F5C710",
    `amber` = "#F5C710"
)


round_df <- function(df, digits) {
  nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
  df[,nums] <- round(df[,nums], digits = digits)
  (df)
}


round_to_places <- function(x, places) {
  # Remove floating point errors
  x <- round(x, 12)
  
  # Initialize output  
  out <- rep_len("", length(x)) 
  
  # Handle NAs  
  out[is.na(x)] <- NA
  
  # Handle infinities
  inf <- is.infinite(x)
  out[inf & x > 0] <- "Inf"
  out[inf & x < 0] <- "-Inf"
  
  # Special cases
  finite <- !inf & !(is.na(x))
  
  # Round numbers
  x <- round(x, places)
  
  # Format numbers
  sgn <- sign(x)
  ints <- trunc(x)
  decs <- round(abs(x - ints) * 10^places)
  
  if (places > 0) {
    out[finite] <- paste0(ifelse(sgn[finite] >= 0, " ", "-"),
                          ints[finite], 
                          ".", 
                          decs[finite], 
                          strrep(0, places - nchar(as.integer(decs[finite])))
    )
  } else {
    out[finite] <- as.character(ints[finite])
  }
  
  return(out)
}

########################## DEBUGGING
round_to_places <- function(x, places) {
  return(as.character(round(x,12)))
}

get_data_for_cov_table <- function(offset = 1) {
  # set random number generator seed
  set.seed(92401)
  set.seed(16633)
  set.seed(2686)
  set.seed(997)
  
  # set parameters
  n <- 10
  rho <- 0.99
  mu <- 0
  sigma <- 3
  
  # build population correlation matrix
  tmp.r <- matrix(rho, n, n)
  tmp.r <- tmp.r^abs(row(tmp.r)-col(tmp.r))
  
  # simulate correlated normal random data
  x1 <- round(mvrnorm(1, rep(mu,n), sigma^2 * tmp.r),1) 
  
  # build a data frame
  df <- data.frame(t = 1:length(x1),
                   x = x1,
                   y = lead(x1, offset)) %>%
    mutate(
      xx = x - mean(x),
      xx2 = xx^2,
      yy = y - mean(x),
      # yy2 = yy^2,
      xy = xx * yy
    ) %>% 
    dplyr::select(t, x, y, xx, xx2, yy, xy)
  
  return(df)
}

make_cov_table_df <- function(df, offset=1, decimals_1st_order = 5, decimals_2nd_order = 5) {
  # Color vector
  oi_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#F5C710", "#CC79A7", "#999999")
  
  df_summary <- df %>% 
    summarize(
      x = sum(x),
      y = sum(y, na.rm = TRUE),
      xx = sum(xx),
      yy = sum(yy, na.rm = TRUE),
      xx2 = sum(xx2),
      # yy2 = sum(yy2, na.rm = TRUE),
      xy = sum(xy, na.rm = TRUE)
    ) %>% 
    # round_df(3) %>% 
    mutate(t = paste0("sum")) %>% 
    mutate(
      t = paste0("sum"),
      x = round_to_places(x, 1),
      y = round_to_places(y, 1),
      xx = round_to_places(xx, decimals_1st_order),
      xx2 = round_to_places(xx2, decimals_2nd_order),
      yy = round_to_places(yy, decimals_1st_order),
      # yy2 = round_to_places(yy2, decimals_2nd_order),
      xy = round_to_places(xy, decimals_2nd_order)
    ) %>% 
    dplyr::select(t, x, y, xx, xx2, yy, xy)
  
  df %>%
    mutate(
      t = as.character(t),
      x = round_to_places(x, 1),
      y = round_to_places(y, 1),
      xx = round_to_places(xx, decimals_1st_order),
      xx2 = round_to_places(xx2, decimals_2nd_order),
      yy = round_to_places(yy, decimals_1st_order),
      # yy2 = round_to_places(yy2, decimals_2nd_order),
      xy = round_to_places(xy, decimals_2nd_order)
    ) %>% 
    mutate(
      x = cell_spec(x, 
                    color = case_when(
                      is.na(x) ~ "#999999",
                      TRUE ~ oi_colors[( row_number() + 0 ) %% 9 + 1]
                    )
      ),
      y = cell_spec(y, 
                    color = case_when(
                      is.na(y) ~ "#999999",
                      TRUE ~ oi_colors[( row_number() + offset ) %% 9 + 1]
                    )
      )
    ) %>% 
    mutate(
      # x = ifelse(row_number() > nrow(.) - offset, paste0("[",x,"]"), x),
      y = ifelse(row_number() > nrow(.) - offset, NA, y),
    ) %>% 
    replace(., is.na(.), "â€”") %>%
    bind_rows(df_summary) %>% 
    rename(
      "x_t" = x,
      "x_{t+k}" = y,
      # paste0("x_{t+", offset, "}") = y,
      "x_t-mean(x)" = xx, 
      "(x_t-mean(x))^2" = xx2, 
      "x_{t+k}-mean(x)" = yy,
      # "(x_{t+k}-mean(x))^2" = yy2, 
      "(x-mean(x))(x_{t+k}-mean(x))" = xy
    ) %>%
  return()
}

# Eliminates the values in columns 3 onward for a specified row_num
make_blank_row_in_cov_table <- function(df, row_num) {
  for (col_num in 3:ncol(df)) {
    df[row_num, col_num] = ""
  }
  return(df)
}

# Displays the kable table
display_table <- function(df) {
  df %>% 
    knitr::kable(format = "html", align='ccccccc', escape = FALSE, width = NA) %>%
    kable_styling(full_width = FALSE, "striped") 
}

# Compute summary values
compute_summaries <- function(df, digits = 4) {
  df %>% 
    summarize(
      mean_x = mean(x),
      mean_y = mean(y, na.rm = TRUE),
      ss_x = sum(xx2),
      # ss_y = sum(yy2, na.rm = TRUE),
      ss_xy = sum(xy, na.rm = TRUE),
      c_0 = sum(xx2) / nrow(.),
      c_k = sum(xy, na.rm = TRUE) / nrow(.),
      r_k = c_k / c_0
    ) %>% 
    round_df(digits)
}

```


## Learning Outcomes

<details>
<summary>Explain the theoretical implications of autocorrelation for the estimation of time series statistics</summary>
    -   Explain how positive autocorrelation leads to underestimation of variance in short time series
    -   Explain how negative autocorrelation can improve efficiency of sample mean estimate
</details>
<details>
<summary>Explain why there is not one correct model to describe a time series</summary>
    -   Explain why there can be several suitable models for a given time series
</details>
<details>
<summary>Compute the covariance of sums of random variables</summary>
    -   Define the covariance of sums of random variables.
</details>
<details>
<summary>Interpret correlograms to identify significant lags, correlations, trends, and seasonality</summary>
    -   Create a correlogram
    -   Interpret a correlogram
    -   Define a sampling distribution
    -   State the sampling distribution of rk
    -   Explain the concept of a confidence interval
    -   Conduct a single hypothesis test using a correlogram
    -   Describe the problems associated with multiple hypothesis testing in a correlogram
    -   Differentiate statistical and practical significance
    -   Diagnose non-stationarity using a correlogram
</details>



## Preparation

-   Read Sections 2.2.5 and 2.3-2.5 (No new reading assignment)


<!-- ## Learning Journal Exchange (10 mins) -->

<!-- -   Review another student's journal -->
<!-- -   What would you add to your learning journal after reading your partner's? -->
<!-- -   What would you recommend your partner add to their learning journal? -->
<!-- -   Sign the Learning Journal review sheet for your peer -->


## Introduction (5 mins)


### Correlograms

-   The table below gives the sample autocorrelation function, acf, for the data set from the previous lesson. Use these values to sketch a correlogram in your Learning Journal. The figure below can help you begin.

```{r}
#| echo: false

x <- c( 4.4, 4.2, 4.2, 4, 4.4, 4.7, 4.9, 5.3, 5.4, 5.5 )
df <- data.frame(x = x)

z <- acf(x, plot=FALSE, type = "correlation") 
# acf(cov_df$x, plot=TRUE, type = "correlation") ## Solution

# z

z$acf %>% 
  data.frame() %>% 
  round_df(3) %>% 
  rename("acf" = ".") %>% 
  mutate(
    k = row_number() - 1,
    acf = as.character(acf)
  ) %>% 
  pivot_wider(names_from = k, values_from = acf) %>% 
  # mutate("4" = "_____") %>% 
  display_table()

ggplot(data = df, aes(x = seq_along(x), y = acf(x, plot = FALSE)$acf)) +
  # geom_col() +
  ylim(-1, 1) +
  scale_x_continuous(breaks = 0:9) + 
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1)) + 
  geom_segment(aes(x = 0, y = 0, xend = 9, yend = 0)) + ## Hack
  geom_hline(yintercept = 0, linetype = "solid", linewidth=1, color = "black") +
  geom_hline(yintercept = (2.6/4.2), linetype = "dashed", linewidth=1, color = "#0072B2") +  # Texbooks says these lines should be at (-0.1 +/- 2/sqrt(10)). Used +/-(2.6/4.2), based on measurements made visually with a ruler from the figure generated by R.
  geom_hline(yintercept = (-2.6/4.2), linetype = "dashed", linewidth=1, color = "#0072B2") +
  labs(x = "Lag", y = "ACF") +
  # theme_bw()   
  # theme(panel.grid.major.x = element_blank(), panel.grid.major.y = element_blank())
  theme_bw() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank()
  )
```

<!-- -   Finish a partially-created correlogram with the r_k values computed -->

-   Are any of the autocorrelations statistically significant? If so, which one(s)?

## Application: Chocolate Search Trends

::: callout-caution
## TYSON: We need to read in the chocolate search trends data, decompose it, then compute the autocorrelations on residuals. What do we need to do to make this work?
:::

-   Is there a trend in the data? If so, speculate about the cause of this trend.
-   Is there evidence of seasonal variation? If so, propose an explanation for the seasonal variation.
-   What do the spikes in the correlogram tell us about this time series?
-   Is there evidence of autocorrelations in the data after removing the trend and seasonal variation?
-   There are two exceptionally large spikes in the observed data. Can you identify a cause for these spikes?


## Recap (5 mins)

-   Review objectives and key points
-   Review the definitions of autocovariance, autocorrelation
-   Discuss autocorrelation in the time series context
